<html>
<br>
<br>    ################################################################################
<br>    ##
<br>    ## MetPX Copyright (C) 2004-2006  Environment Canada
<br>    ## MetPX comes with ABSOLUTELY NO WARRANTY; For details type see the file
<br>    ## named COPYING in the root of the source directory tree.
<br>    ##
<br>    ##
<br>    ## Name   : howTo.py 
<br>    ##  
<br>    ## Author : Nicholas Lemay  
<br>    ##
<br>    ## Last update : December 11th 2006
<br>    ##
<br>    ##
<br>    ## Goal   : Show proper usage of the library to users.
<br>    ##          
<br>    ##                    
<br>    ################################################################################
<br>    
<br>    
<br>    How to use the stats library, step by step : 
<br>    --------------------------------------------
<br>    
<br>    --------------------------
<br>    |Step 1 - Data collection. |
<br>    --------------------------
<br>        
<br>        ------------------
<br>        |Preliminary steps |
<br>        ------------------
<br>        
<br>        Data collection must be done localy. Data collected will be saved in
<br>        pickle files.
<br>        
<br>        Step 1.1 - Connect on the machine where you want to collect data  
<br>        
<br>        Step 1.2 - Go in the /apps/px/lib/stats/ folder
<br>        
<br>        Step 1.3 - Run the following to see how pickleUpdater.py works 
<br>                python pickleUpdater.py -h 
<br>        
<br>        Step 1.4 - Run pickleUpdater.py with the wanted parameters to update
<br>                the needed clients.
<br>    
<br>            
<br>        ---------------------------------------------------------
<br>    | How to have pickleUpdater.py do what you want it to do: |
<br>        ---------------------------------------------------------
<br>            
<br>            Step 1.4.1
<br>                Update All tx or rx client found on the machine up to now :
<br>                        pickleUpdater.py -f tx
<br>                        pickleUpdater.py -f rx
<br>                
<br>                Note These two commands will be the most used of any commands
<br>                that can be used with pickle updates.        
<br>            
<br>            Step 1.4.2
<br>                update a certain tx client :
<br>                
<br>                pickleUpdater.py -f tx -c satnet
<br>                pickleUpdater.py -f rx -c satnet
<br>            
<br>            
<br>            Step 1.4.3
<br>                update a certain tx client up to a certain date :
<br>                pickleUpdater.py -f tx -c satnet -d "2006-08-08 12:15:00"
<br>                
<br>                ***Very usefull to start off a new client. At first, you use
<br>                pickleUpdater with  the first hour where the client started
<br>                as parameter. 
<br>                
<br>                Once this has been done, you update it up to now using : 
<br>                        pickleUpdater.py -f tx -c satnet
<br>                and the application will update the data up to now no matter
<br>                how many hours or days there has been since the first hour.      
<br>            
<br>                
<br>            Step 1.4.4
<br>                Update only one type of data for a client
<br>                Note : not recommended since it limits the graphics that can be 
<br>                    later produced 
<br>                
<br>                pickleUpdater.py -f tx -c satnet -t bytecount             
<br>            
<br>            
<br>    
<br>    -------------------------------------------------------------------------    
<br>    | Step 2 - Getting the collected data on your graphic producing machine. |
<br>    -------------------------------------------------------------------------
<br>        
<br>        --------------------------------------
<br>        |Preliminary steps (done in this order)|
<br>        --------------------------------------
<br>        Step 2.1 - Connect to the graphic producing machine.
<br>        
<br>        Step 2.2 - Go in the /apps/px/lib/stats/ folder. 
<br>        
<br>        Step 2.3 - Run the following to see how pickleSynchroniser.py works :
<br>                python pickleSynchroniser.py -h 
<br>        
<br>        Step 2.4 - Run pickleSynchroniser.py with the parameters wanted to 
<br>                get the desired results.
<br>    
<br>        --------------------------------------------------------------
<br>    | How to have pickleSynchroniser.py do what you want it to do: |
<br>        --------------------------------------------------------------
<br>        Example 1 :
<br>            
<br>                Update data from all machines :
<br>                
<br>                pickleSynchroniser.py 
<br>                
<br>                Note : this will be the most used call to pickleSyncrhoniser.
<br>            
<br>        Example 2
<br>                
<br>                Update data from a specific machine :
<br>                
<br>                pickleSynchroniser.py -m "pds5"
<br>            
<br>                Note : Might be obligatory if all machines have different ssh logins.
<br>            
<br>        Example 3
<br>                
<br>                Update data from a specific client of a machine 
<br>                
<br>                pickleSynchroniser.py -m "pds5" -c "satnet"
<br>                
<br>                Note : this will make updating very long if done client per client
<br>                    and is thus not recommended.
<br>            
<br>                
<br>        Example 4
<br>            
<br>                Specify wich ssh login to use when connecting to the machines to
<br>                update :
<br>                
<br>                pickleSynchroniser.py -m "pds5" -c "satnet" -l "myLogin"
<br>            
<br>                Note : It is recommended that you use a login that has instant 
<br>                    access tothe machine when using pickleSynchroniser.py or else
<br>                    automatic updates using crontab will be useless since user
<br>                    needs to type password for every ssh connection... 
<br>    
<br>                    
<br>    ------------------------------------            
<br>    | Step 3  Feeding the databases.     |
<br>    ----------------------------------- 
<br>                    
<br>        ------------------
<br>    |Preliminary steps |
<br>        ------------------
<br>        Step 3.1 - Connect to the machine containing the pickles
<br>                ( usually the graphics machine).
<br>        
<br>        Step 3.2 - Go in the /apps/px/lib/stats/ folder. 
<br>        
<br>        Step 3.3 - Run the following to see how transferPickleToRRD.py works :
<br>                python transferPickleToRRD.py -h 
<br>        
<br>        Step 3.4 - Run transferPickleToRRD.py with the parameters wanted to
<br>                transfer pickled data into rrd databases.  
<br>    
<br>        --------------------------------------------------------
<br>        | How to tranfer the pickles you want :                  |
<br>        --------------------------------------------------------     
<br>            Example 1
<br>            
<br>            python transferPickleToRRD.py -m machine
<br>            
<br>            This tranfers all the currently active tx and rx clients/sources pickle 
<br>            files that are found between the time of he last transfer up to the top
<br>            of the current hour. This is the simplest and most used option of
<br>            transferPickleToRRD.py
<br>            
<br>            
<br>            Example 2
<br>            
<br>            python transferPickleToRRD.py -m machine -e "2006-12-10 01:00:00"
<br>            
<br>            Same as above but for files between time of last update and 2006-12-10
<br>            01:00:00.This is usefull for testing purposes, if more recent pickels 
<br>            aren't available at the moment or if user wants to update database for
<br>            shorter periods as to not have to transfer data for hours on end. 
<br>            
<br>            Example 3
<br>            python transferPickleToRRD.py -m machine -c client -f tx 
<br>            
<br>            Same as #1 except that we only transfer the pickles for a single
<br>            tx client. 
<br>                
<br>            
<br>                                
<br>    ----------------------------- 
<br>    |Step 4- Producing Graphics. |
<br>    -----------------------------  
<br>        
<br>        ------------------------------------------------ 
<br>        | 4.1 Producing graphics based on pickle files.  |         
<br>        ------------------------------------------------   
<br>        
<br>            ------------------
<br>            |Preliminary steps |
<br>            ------------------
<br>            Step 4.1.1 - Connect to the graphic producing machine.
<br>            
<br>            Step 4.1.2 - Go in the /apps/px/lib/stats/ folder. 
<br>            
<br>            Step 4.1.3 - Run the following to see how generateGRaphics.py works 
<br>                        python generateGraphics.py -h 
<br>            
<br>            Step 4.1.4 - Run generateGraphics.py with the parameters wanted to 
<br>                        get the desired graphics
<br>        
<br>            --------------------------------------------------------
<br>            | How to have  the graphics you want:                   |
<br>            --------------------------------------------------------
<br>                Example 1
<br>                    produce a graphic for satnet, for the past 12 hours for each
<br>                    of the data types supported by tx files coming from data 
<br>                    collected on all machines.
<br>                    
<br>                    generateGraphics.py -c satnet
<br>                    
<br>                Example 2
<br>                    produce a graphic for satnet and amis, for the past 12 hours for
<br>                    each of the data type supported by tx files coming from data 
<br>                    collected on all machines.
<br>                    
<br>                    generateGraphics.py -c "satnet,amis"
<br>        
<br>                Example 3
<br>                    produce a graphic for satnet, for the past 5 hours for each of
<br>                    the data type supported by tx files coming from data collected
<br>                    on all machines.
<br>                    
<br>                    generateGraphics.py -c satnet -s 5
<br>                    
<br>                Example 4
<br>                    produce a graphic for client, for the past 12 hours for each of
<br>                    the data type supported by rx files coming from data collected
<br>                    on all machines.
<br>                    
<br>                    generateGraphics.py -c satnet -f rx   
<br>                    
<br>                Example 5
<br>                    produce a graphic for satnet, for the past 12 hours for each of 
<br>                    the data type supported by tx files coming from data collected 
<br>                    on pds5 machine.
<br>                    
<br>                    generateGraphics.py -c satnet -m pds5
<br>                    
<br>                Example 6
<br>                    produce a graphic for satnet, for the past 12 hours for each of
<br>                    the data type supported by tx files coming from data collected 
<br>                    on all machines. Use only data relative to product that contain
<br>                    the name WXB 
<br>                    
<br>                    
<br>                    generateGraphics.py -c satnet  -p WXB   
<br>                    
<br>                    
<br>                Example 7
<br>                    produce a graphic for satnet, for the entire day of october 8th
<br>                    2005 for each of the data type supported by tx files coming from
<br>                    data collected on all machines.
<br>                    
<br>                    generateGraphics.py -c satnet -s 24 -d "2005-10-08 01:00:00"
<br>                    
<br>                
<br>                Example 8
<br>                    produce the same graphic but only for latency 
<br>                    
<br>                    generateGraphics.py -c satnet -s 24 -d "2005-10-08 01:00:00"
<br>                    -t latency     
<br>        
<br>                
<br>                Example 9
<br>                    produce the same graphic but only for latency and errors
<br>                    
<br>                    generateGraphics.py -c satnet -s 24 -d "2005-10-08 01:00:00"
<br>                    -t "latency,errors"
<br>                                
<br>                            
<br>                Example 10
<br>                    5 hour graphic, requested at 5h15 on august 8th 2006, for 
<br>                    rxclient, using data collected only for products containing 
<br>                    WXBO in their name, using data collected on pds5 and 6 
<br>                    
<br>                    generateGraphics.py -c rxclient -d "2006-08-08 05:15:00" -f rx
<br>                    -m "pds5,pds6" -p WXBO -s 5 -t "bytecount,errors"   
<br>    
<br>                
<br>                
<br>        ------------------------------------------------------------- 
<br>        | 4.2 Producing graphics based on databases.                  |         
<br>        -------------------------------------------------------------   
<br>        
<br>            ------------------
<br>            |Preliminary steps |
<br>            ------------------
<br>            Step 4.2.1 - Connect to the graphic producing machine.
<br>            
<br>            Step 4.2.2 - Go in the /apps/px/lib/stats/ folder. 
<br>            
<br>            Step 4.2.3 - Run the following to see how generateRRDGraphics.py works :
<br>                        generateRRDGraphics.py -h 
<br>            
<br>            Step 4.2.4 - Run generateRRDGraphics.pywith the parameters wanted
<br>                        to get the desired graphics     
<br>            
<br>            -------------------------------------------------------
<br>            | How to have the graphics you want :                   |
<br>            -------------------------------------------------------
<br>                
<br>                Example 1
<br>                
<br>                python generateRRDGraphics.py -m -l -f tx --machines 'pds5,pds6'
<br>                -e '2006-10-10 01:00:00'
<br>                
<br>                Creates monthly graphics for all the tx client from the combined
<br>                data of the files found on pds5 and pds6. Since this is a tx client,
<br>                5 graphic types will be created : errors, bytecount, filecount, 
<br>                filesOverMaxLatency and latency.
<br>                
<br>                The end of the week will be  2006-10-10 01:00:00. Graphics will 
<br>                show all data comprised between 2006-10-03 01:00:00 and 2006-10-10
<br>                01:00:00. The -l option creates a symbolic link to the 
<br>                graphics so that it can be viewed from the web page interface. 
<br>                
<br>                
<br>                Example 2
<br>                
<br>                python generateRRDGraphics.py -m -l -f rx --machines 'pds5,pds6' 
<br>                -e '2006-10-10 01:00:00'
<br>                
<br>                Same as 1 but with rx sources. This will generate 3 graphic types : 
<br>                bytecount, errors and filecount.
<br>                
<br>                
<br>                Example 3
<br>                python generateRRDGraphics.py -m -l -f tx --machines -c client
<br>                'pds5,pds6' -e '2006-10-10 01:00:00'
<br>                
<br>                Same as 1 but only for a single specific tx client.    
<br>            
<br>                Example 4 
<br>                
<br>                python generateRRDGraphics.py -m -l -f tx --machines 'pds5,pds6'
<br>                -e '2006-10-10 01:00:00' --totals
<br>                
<br>                Same as 1 except that instead of creating a single graphic per tx
<br>                client, it draws a single graphics for all the clients based on the 
<br>                total of all the data associated with all the tx clients.
<br>                
<br>            
<br>            
<br>    ----------------------------     
<br>    | Step 5 - Generating the    |
<br>    | the web pages.             |
<br>    ----------------------------    
<br>    
<br>        ------------------
<br>        |Preliminary steps |
<br>        ------------------
<br>        Step 5.1 - Connect to the graphic producing machine.
<br>        
<br>        Step 5.2 - Go in the /apps/px/lib/stats/ folder. 
<br>        
<br>        Step 5.3 - Get the graphics required by the web pages by running
<br>                python getGraphicsForWebPages.py
<br>        
<br>        -----------------------
<br>        | Updating the webPages |
<br>        -----------------------
<br>        
<br>        Step 5.4 - Update the web page containing daily graphics by running 
<br>                python dailyGraphicsWebPage.py
<br>        Step 5.5 - Update the web page containing weekly graphics by running
<br>                python weeklyGraphicsWebPage.py
<br>        Step 5.6 - Update the web page containing monthly graphics by running
<br>                python monthlyGraphicsWebPage.py
<br>        Step 5.7 - Update the web page containing yearly graphics by running
<br>                python yearlyGraphicsWebPage.py
<br>                        
<br>        
<br>        
<br>                
<br>    --------------------   
<br>    | Step 6 - Utilities |
<br>    --------------------
<br>        
<br>        6.1 pickled times
<br>        
<br>            To see the content of the pickled-times file wich contains the time 
<br>            of the last update of every client, on a specific machine use the
<br>            folowing :
<br>            
<br>            Step 6.1.1 - Connect on the machine.
<br>            Step 6.1.2 - Go to the /apps/px/lib/stats/ folder. 
<br>            Step 6.1.3 - run pickledTimesViewer.py 
<br>            
<br>            This is very usefull for debugging.
<br>        
<br>            
<br>        6.2 pickleViewer    
<br>            To see the content of pickle files containg the collected data on a
<br>            specific machine use the folowing :
<br>            
<br>            Step 6.2.1 - Connect on the machine.
<br>            Step 6.2.2 - Go to the /apps/px/lib/stats/ folder. 
<br>            Step 6.2.3 - Run pickleViewer.py -h to sse how it works
<br>            Step 6.2.4 - Run pickleSynchroniser.py with the parameters wanted to 
<br>                        get the desired results:
<br>        
<br>            --------------------------------------------------------
<br>            | How to have pickleViewer.py do what you want it to do: |
<br>            --------------------------------------------------------
<br>            Example 1
<br>                View a specific pickle
<br>                pickleViewer.py /apps/px/stats/pickles/amis/20060808/tx/lvs1-dev_00
<br>                    
<br>            Example 2
<br>                Dump the content of the pickle in a text file for easier viewing.
<br>                pickleViewer.py /apps/px/stats/pickles/amis/20060808/tx/lvs1-dev_00 
<br>                /myHomeFolder/outputFile.txt.
<br>            
<br>            This is very usefull for debugging.
<br>            
<br>            
<br>        6.3 pickleCleaner
<br>            This file is to be used to cleanup the saved pickle files. 
<br>            Simply run pickleCleaner.py and it will remove any folder containing
<br>            pickle files older than x days.
<br>            
<br>            
<br>        6.4 clean_dir.pxl
<br>            This file is to be used to remove from any folder the files that are
<br>            older than x amount of time.
<br>            
<br>            See /apps/px/etc/clean.conf to see how to set the config files so that
<br>            files a removed correctly.    
<br>        
<br>            
<br>        6.5 setTimeOfLastUpdate
<br>            This file is used to modify the content of the pickled times file.
<br>            If done properly, this will set back the time of the last update of 
<br>            the pickle files and for pickleUpdater.py to regenerate pickle files
<br>            during the next update. This will be very usefull if errors are found
<br>            within pickle files during monitoring and that a user has corrected the
<br>            cause and wants to correct the pickle files.
<br>            
<br>            python setTimeOfLastUpdate.py "2006-10-10 01:00:00"
<br>        
<br>            
<br>        6.6 backupRRDDatabases
<br>            Backups the currrent databases. One a time entry has been filled within
<br>            an rrd database, it cannot be modified. Because of that, database 
<br>            backups should be  done rather frequently so that if an error is 
<br>            inserted within the db a user can use the back up database and insert 
<br>            the corrected value at the next update.
<br>            
<br>            python backupRRDDatabases.py
<br>        
<br>            
<br>        6.7 restoreRoundRobinDatabases.py
<br>            This program is to be used in conjunction with the backupRRDDatabases
<br>            utility. When a database is backed up, the backup file will have the
<br>            time of the backup witten in it's name. When a user wants to restore
<br>            that database it only needs to specify the time of the backup to the
<br>            restoreRoundRobinDatabases utility. 
<br>            
<br>            python restoreRoundRobinDatabases.py "2006-10-10 01:00:00"
<br>            
<br>            
<br>    --------------------------------------
<br>    | Step 7 Making it all work together : |
<br>    --------------------------------------
<br>    
<br>        7.1 launchGraphCreation.py
<br>        
<br>            As previously explained, for a proper se of all the functions
<br>            of the stats library, each step should be done in the right order.
<br>            The suggested order being used right now in the launchGraphCreation.py 
<br>            file is the following 
<br>            
<br>            1- Pickle update
<br>            2- Pickle synchronisation
<br>            3- Database updates
<br>            4- Graphic generations
<br>            5- Graphic update for web pages
<br>            6- Web pages
<br>            7(optional)Upload of some graphic files to a machine that requires them.
<br>            
<br>            The above program is launched once per hour using a crontab entry.
<br>            The current entry on one of the machines is the following :
<br>            8 * * * * /apps/px/lib/stats/launchGraphCreation.py > /dev/null 2>&1
<br>        
<br>            Note : PYTHONPATH environment wich is needed by python should be declared
<br>                in crontab file or else programs will not work.       
<br>    
<br>            
<br>    -------------------
<br>    | Step 8 Monitoring |
<br>    -------------------
<br>        
<br>        8.1 statsMonitor.py
<br>        
<br>            This program is to be used to detect any anomalies within the different 
<br>            tasks done within the stats library.
<br>            
<br>            It is recommended to run this program once a day to keep execution time
<br>            of the monitoring program short and also to make sure errors don't
<br>            corrupt the data and graphics for a long time.  
<br>            
<br>            See /apps/px/stats/statsMonitoring/statsMonitoring.conf to see how to 
<br>            configure the statsMonitor program.
<br>    
<br>    
<br>    
<br>    
<br>    
<br>    
<br>    
<br></html><br>